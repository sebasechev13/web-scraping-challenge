{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splinter \n",
    "import selenium \n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect the chrome driver\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to the url nasa mars page to web scrape\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get html code from the webpage and parse it \n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "#get the first news title and first news summary \n",
    "result = soup.find('div',  class_ = 'list_text')\n",
    "\n",
    "news_title = result.find('a', target = '_self').text\n",
    "news_p = result.find('div', class_='article_teaser_body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to the url for the featured image \n",
    "url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get html code from it \n",
    "html2 = browser.html\n",
    "soup2 = BeautifulSoup(html2,'html.parser')\n",
    "\n",
    "#get the ending of the url to link to the image \n",
    "result2 = soup2.find('article',  class_ = 'carousel_item')\n",
    "class1 = result2.find('a', class_=\"button fancybox\").text\n",
    "# Identify and return link to listing\n",
    "link = result.a['data-fancybox-href']\n",
    "\n",
    "featured_image_url = 'https://www.jpl.nasa.gov+link'+ link\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "request.get('https://twitter.com/marswxreport?lang=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to the twitter of mars weather \n",
    "url3 = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://twitter.com/marswxreport?lang=en').text\n",
    "html1 = BeautifulSoup(html,'html.parser')\n",
    "news1 = html1.find('p',  class_ = \"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "next_text = news1.text\n",
    "news5 = news1.find_all(\"a\")\n",
    "text=(\"\")\n",
    "text1=(\"\")\n",
    "for news in news5:\n",
    "    text1 = news.text\n",
    "    text = text+text1\n",
    "mars_weather = next_text.replace(text,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The seasonal cycle of Marsâ€™ atmospheric pressure explained '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.replace(news5,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get html code from it \n",
    "html3 = browser.html\n",
    "soup3 = BeautifulSoup(html3,'html.parser')\n",
    "\n",
    "#get the first tweet on the page \n",
    "result3 = soup3.find('div',  class_ = 'js-tweet-text-container')\n",
    "mars_weather = result3.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to the url to get mars facts\n",
    "url4 = 'https://space-facts.com/mars/'\n",
    "browser.visit(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get html code from it \n",
    "html4 = browser.html\n",
    "soup4 = BeautifulSoup(html4,'html.parser')\n",
    "\n",
    "#get the first tweet on the page \n",
    "result4 = soup4.find('table')\n",
    "mars_facts = result4.to_html(header = False, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_df = pd.read_html(\"https://space-facts.com/mars/\")[0]\n",
    "mars_df.columns=[\"Description\", \"Value\"]\n",
    "mars_df.set_index(\"Description\", inplace=True)\n",
    "mars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to the url to get Mars Hemispheres images\n",
    "url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get html code from it \n",
    "html5 = browser.html\n",
    "soup5 = BeautifulSoup(html5,'html.parser')\n",
    "\n",
    "#find all  the listings in the html \n",
    "result5 = soup5.find_all('div', class_=\"item\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty list \n",
    "hemisphere_image_urls = []\n",
    "# iterate through the four results and go to their link to get the image url\n",
    "for result in result5:\n",
    "    link = result.a['href']\n",
    "    browser.visit('https://astrogeology.usgs.gov'+link)\n",
    "    html6 = browser.html\n",
    "    soup6 = BeautifulSoup(html6,'html.parser')\n",
    "    first = soup6.find('div',class_=\"downloads\")\n",
    "    image_url = first.a['href']\n",
    "    title = soup6.find('h2', class_= 'title').text\n",
    "    post = {\"title\": title, \"img_url\": image_url }\n",
    "    hemisphere_image_urls.append(post)\n",
    "    \n",
    "    browser.back()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
